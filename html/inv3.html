False discoveries are inevitable. For the most part their frequency is driven by the number of false hypotheses.
It is hard to know whether a hypothesis is true or false and so there are no really good ways of preventing false discoveries.
Instead, we must check up on a promising looking result.
<br><br>
There are two ways to do this:           
<ul style=margin:0px;>
<li> Replication: repeat the result and prefer the new result
<li> Meta-analysis: repeat the result and combine the new result with the old one
</ul>
How do the two compare?
<br><br>
<b>In the first part of this investigation</b>, we look at replication.
The process only looks at results that were significant in the first place. 
There are 3 types of outcome: ns no follow-up; sig, then ns; sig then sig.
If the population effect size is zero, then the first two outcomes are correct.
If the population effect size is not zero, then the third outcome is correct.
How many correct results does replication produce?
<br>
Replication is widely used and accepted, but is that entirely safe?
<br><br>
<b>In the second part of this investigation</b>, we look at meta-analysis.
Although normally used with many studies, the process can be applied to just two studies
and we can think of it as a way of combining an original study and the replication.
As before, there are three possible outcomes and as before, we ask how many correct results meta-analysis produces.
<br><br>
What we see is the familiar issue of a trade-off between false discoveries (very few for replication)
and false misses (very many for replication).
Actually, the same trade-off exists for just one study when one changes alpha (normally 0.05).
<br>
<br>
More information 
<a href=
"https://doingpsychstats.wordpress.com/investigation-BelievableResults,'/"
 target="_blank">
here
</a>
 and leave any comments 
<a href=
"https://doingpsychstats.wordpress.com/investigation-BelievableResults,'/#respond"
 target="_blank">
here
</a>